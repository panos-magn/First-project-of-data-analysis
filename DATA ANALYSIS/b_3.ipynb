{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Z3mjXZZAsb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "import keras as kr\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import SimpleRNN\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import io"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omPNdGxCa2DU"
      },
      "source": [
        "data=pd.read_excel('data_akbilgic.xlsx',header=1)\n",
        "data=data.loc[0:529] #keep the rows from 0 to 529 (first 530 rows)\n",
        "data=data.drop(columns=['date']) #drop date column date"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LO24dbobB23"
      },
      "source": [
        "data.reset_index(inplace=True)#add index\n",
        "\n",
        "plt.plot(data['ISE'])\n",
        "plt.savefig('./ise_plot.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leeweMtPbgxx"
      },
      "source": [
        "df = data['ISE'].to_frame(name='ISE')\n",
        "df_1 = df.copy() #MAKE A COPY\n",
        "scaler = MinMaxScaler(feature_range=(0, 1)) #SCALING OUR DATA\n",
        "df = scaler.fit_transform(np.reshape(df['ISE'].values, (df.shape[0], 1)))\n",
        "df = pd.DataFrame(data=df, columns=['ISE'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IWfePHEb4Zj"
      },
      "source": [
        "def timeseries_to_supervised(df, n_in, n_out):\n",
        "   agg = pd.DataFrame()\n",
        "\n",
        "   for i in range(n_in, 0, -1):\n",
        "      df_shifted = df.shift(i).copy()\n",
        "      df_shifted.rename(columns=lambda x: ('%s(t-%d)' % (x, i)), inplace=True)\n",
        "      agg = pd.concat([agg, df_shifted], axis=1)\n",
        "\n",
        "   for i in range(0, n_out):\n",
        "      df_shifted = df.shift(-i).copy()\n",
        "      if i == 0:\n",
        "         df_shifted.rename(columns=lambda x: ('%s(t)' % (x)), inplace=True)\n",
        "      else:\n",
        "         df_shifted.rename(columns=lambda x: ('%s(t+%d)' % (x, i)), inplace=True)\n",
        "      agg = pd.concat([agg, df_shifted], axis=1)\n",
        "   agg.dropna(inplace=True)\n",
        "   return agg\n",
        "n_in = 4 #Timeseries consists of 4 input steps.\n",
        "n_out = 1\n",
        "sdf = timeseries_to_supervised(df, n_in, n_out)\n",
        "X, y = sdf[[('ISE(t-%d)' % i) for i in range(4, 0, -1)]].values, sdf['ISE(t)'].values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB_wvGsFb_Sq"
      },
      "source": [
        "len_data = X.shape[0]\n",
        "print(len_data)\n",
        "train_size = int(len_data * .5)\n",
        "print (\"Train size: %d\" % train_size)\n",
        "print (\"Test size: %d\" % (len_data - train_size))\n",
        "\n",
        "xtr, ytr = X[:train_size, :], y[:train_size]\n",
        "xte, yte = X[train_size:, :], y[train_size:]\n",
        "print(xtr.shape, ytr.shape)\n",
        "print(xte.shape, yte.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B9X2hIkfbUL"
      },
      "source": [
        "**CONVERT TO 3D NUMPY ARRAYS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9QHKfnwdfzC"
      },
      "source": [
        "samples = train_size\n",
        "steps = 1\n",
        "print(\"Samples\",samples)\n",
        "features_in = 4\n",
        "features_out = n_out\n",
        "xtr = np.reshape(xtr, (samples, steps, features_in))# (Samples,steps,input_features)=(263,1,4)\n",
        "ytr = np.reshape(ytr, (samples, steps, features_out)) # (Samples,steps,output_features)=(263,1,1)\n",
        "print(\"Training data input shape:\",xtr.shape,\"Training data output shape:\", ytr.shape)\n",
        "xte = np.reshape(xte, (samples, steps, features_in))\n",
        "yte = np.reshape(yte, (samples, steps, features_out))\n",
        "print(\"Testing data input shape:\",xte.shape,\"Testing data output shape:\", yte.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQwUpeHrfHHe"
      },
      "source": [
        "**CREATE A SIMPLE RNN MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQw_6eiqdyrH"
      },
      "source": [
        "batch_size = 1 #batch size is 1.The weights are updated 263 times per epoch.\n",
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(units=50, input_shape=(xtr.shape[1], xtr.shape[2]), activation=\"relu\", return_sequences=True))\n",
        "model.add(Dense(50, activation=\"relu\")) #linear activation functio was tested as well.\n",
        "\n",
        "model.add(Dense(1, activation=\"relu\")) #one output neuron since it is a regression problem.\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')#mean squered error is used as loss function.\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRsyckKie6u-"
      },
      "source": [
        "**TRAIN MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLdMtP6cd25k"
      },
      "source": [
        "model.fit(xtr,ytr, epochs=50, batch_size=batch_size, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFwJ4q3ae0Yd"
      },
      "source": [
        "**Make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr9afy0Yd9Ab"
      },
      "source": [
        "trainPredict = model.predict(xtr, batch_size=batch_size)\n",
        "testPredict = model.predict(xte, batch_size=batch_size)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40qQTJwPeAcJ"
      },
      "source": [
        "trainPredict = np.reshape(trainPredict, (samples*steps, features_out))\n",
        "ytr2d = np.reshape(ytr, (samples*steps, features_out))\n",
        "testPredict = np.reshape(testPredict, (samples*steps, features_out))\n",
        "yte2d = np.reshape(yte, (samples*steps, features_out))\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRA3bNugef0Y"
      },
      "source": [
        "**Inverse the normalization of the data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oKo8URueEol"
      },
      "source": [
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainY = scaler.inverse_transform(ytr2d)\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "testY = scaler.inverse_transform(yte2d)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yusoaPQbeIsa"
      },
      "source": [
        "print(\"Test Mean Squared Error: \", mean_squared_error(testY, testPredict))\n",
        "#print(\"Test MSE: \", sum(np.square(testY-testPredict))/testY.shape[0])#computed by hand\n",
        "print(\"Test Mean Absolute Error: \", sum(abs(testY-testPredict))/testY.shape[0])\n",
        "print(\"Test R2 (R-squared.): \", r2_score(testY, testPredict))\n",
        "#print(\"Test R2: \", 1-(sum(np.square(testY-testPredict))/sum(np.square(testY-testY.mean()))))#computed by hand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnqdaJN6eN4L"
      },
      "source": [
        "predicted = np.concatenate((trainPredict,testPredict),axis=0)#Concatenate the training and the testing predictions."
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzfkoeOdebl8"
      },
      "source": [
        "**PLOT THE MODEL WITH TRAINING (LEFT) AND TESTING(RIGHT)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0W4AVYSeS4k"
      },
      "source": [
        "original = np.concatenate((trainY,testY),axis=0)\n",
        "predicted = np.concatenate((trainPredict,testPredict),axis=0)\n",
        "index = range(0, original.shape[0])\n",
        "plt.plot(index,original, 'g')# true predictions\n",
        "plt.plot(index,predicted, 'r') #model predictions\n",
        "plt.axvline(df.index[train_size], c=\"b\")\n",
        "plt.savefig('./rnn_plot.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}